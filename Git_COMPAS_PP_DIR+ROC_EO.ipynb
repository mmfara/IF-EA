{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiJcADOF9LtXnJ2PuCe1j8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmfara/IF-EA/blob/main/Git_COMPAS_PP_DIR%2BROC_EO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMKSCsSh6ESj"
      },
      "outputs": [],
      "source": [
        "# Data handling and visualization\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# AIF360 fairness library\n",
        "from aif360.datasets import StandardDataset, BinaryLabelDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
        "from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing\n",
        "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions import get_distortion_adult\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
        "from aif360.algorithms.inprocessing import ExponentiatedGradientReduction, AdversarialDebiasing\n",
        "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
        "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv(COMPAS dataset)\n",
        "\n",
        "X = data.drop(['two_year_recid'], axis =1)\n",
        "y = data[['two_year_recid']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=101, shuffle =True, stratify = y)\n",
        "\n",
        "dataset_train = pd.concat([X_train, y_train], axis=1)\n",
        "dataset_test = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "dataset_train = dataset_train.reset_index(drop=True)\n",
        "dataset_test = dataset_test.reset_index(drop=True)\n",
        "\n",
        "# Define favorable and unfavorable labels\n",
        "favorable_label = 1\n",
        "unfavorable_label = 0\n",
        "\n",
        "# Define protected attribute names and privileged group\n",
        "protected_attribute_names = ['race']\n",
        "privileged_group = [{'race': 1}]\n",
        "unprivileged_group = [{'race' : 0}]\n",
        "\n",
        "# Convert the training and test set to Binary label datasets\n",
        "dataset_train_bld = BinaryLabelDataset(df=dataset_train,\n",
        "                             label_names=['two_year_recid'],\n",
        "                             favorable_label=favorable_label,\n",
        "                             unfavorable_label=unfavorable_label,\n",
        "                             protected_attribute_names=protected_attribute_names,\n",
        "                             privileged_protected_attributes=privileged_group)\n",
        "\n",
        "dataset_test_bld = BinaryLabelDataset(df=dataset_test,\n",
        "                                      label_names=['two_year_recid'],\n",
        "                                      favorable_label=favorable_label,\n",
        "                                      unfavorable_label=unfavorable_label,\n",
        "                                      protected_attribute_names=protected_attribute_names,\n",
        "                                      privileged_protected_attributes=privileged_group)\n",
        "\n",
        "# Applying DisparateImpactRemover\n",
        "dir = DisparateImpactRemover(repair_level=1, sensitive_attribute=\"race\")\n",
        "\n",
        "# Fit and transform the training data\n",
        "dir_dataset = dir.fit_transform(dataset_train_bld)\n",
        "\n",
        "# Define features and target variable\n",
        "X_train = dir_dataset.features\n",
        "y_train = dir_dataset.labels.ravel()\n",
        "X_test = dataset_test_bld.features\n",
        "y_test = dataset_test_bld.labels.ravel()\n",
        "\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
        "y_train = pd.DataFrame(y_train, columns = y.columns)\n",
        "y_test = pd.DataFrame(y_test, columns = y.columns)\n",
        "\n",
        "dataset_train = pd.concat([X_train_scaled, y_train], axis=1)\n",
        "dataset_test = pd.concat([X_test_scaled, y_test], axis=1)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train['two_year_recid'])\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "y_pred = pd.DataFrame(y_pred, columns=['two_year_recid'])\n",
        "X_test = pd.DataFrame(X_test, columns=X.columns)\n",
        "\n",
        "dataset_test = pd.concat([X_test, y_test], axis=1)\n",
        "dataset_testpred = pd.concat([X_test, y_pred], axis=1)\n",
        "\n",
        "# Convert DataFrames back to AIF360 BinaryLabelDataset\n",
        "dataset_test = BinaryLabelDataset(df=dataset_test,\n",
        "                                          label_names=['two_year_recid'],\n",
        "                                          favorable_label=favorable_label,\n",
        "                                          unfavorable_label=unfavorable_label,\n",
        "                                          protected_attribute_names=protected_attribute_names,\n",
        "                                          privileged_protected_attributes=privileged_group)\n",
        "\n",
        "dataset_testpred = BinaryLabelDataset(df=dataset_testpred,\n",
        "                                         label_names=['two_year_recid'],\n",
        "                                         favorable_label=favorable_label,\n",
        "                                         unfavorable_label=unfavorable_label,\n",
        "                                         protected_attribute_names=protected_attribute_names,\n",
        "                                         privileged_protected_attributes=privileged_group)\n",
        "\n",
        "# Wrap the true labels and the predictions into BinaryLabelDataset objects\n",
        "predictions = dataset_test_bld.copy()\n",
        "predictions.labels = y_pred.reshape(-1,1)\n",
        "\n",
        "# Initialize EqualizedOdds\n",
        "eo = EqOddsPostprocessing(unprivileged_groups=unprivileged_group,\n",
        "                                  privileged_groups=privileged_group, seed = 101)\n",
        "\n",
        "# Fit the EqualizedOdds model\n",
        "test_predictions = eo.fit_predict(dataset_test, dataset_testpred)\n",
        "\n",
        "# Evaluate the classifier's performance with fairness intervention\n",
        "metric_with_fairness = ClassificationMetric(\n",
        "    dataset_test_bld,\n",
        "    test_predictions,\n",
        "    unprivileged_groups=unprivileged_group,\n",
        "    privileged_groups=privileged_group\n",
        ")\n",
        "\n",
        "print(\"Performance with fairness intervention (EqualizedOdds):\")\n",
        "print(\"Accuracy: {:.6f}\".format(metric_predicted_dataset.accuracy()))\n",
        "print(\"Disparate Impact: {:.6f}\".format(metric_predicted_dataset.disparate_impact()))\n",
        "print(\"Mean Difference: {:.6f}\".format(metric_predicted_dataset.mean_difference()))\n",
        "print(f\"Statistical Parity Difference: {metric_predicted_dataset.statistical_parity_difference()}\")\n",
        "print(f\"Equal Opportunity Difference: {metric_predicted_dataset.equal_opportunity_difference()}\")\n",
        "print(f\"Predictive Equality: {metric_predicted_dataset.false_positive_rate_difference()}\")\n",
        "print(\"Difference in True Positive Rates (Unprivileged - Privileged) = %f\" % metric_with_fairness.true_positive_rate_difference())\n",
        "print(\"Difference in False Positive Rates (Unprivileged - Privileged) = %f\" % metric_with_fairness.false_positive_rate_difference())\n",
        "\n",
        "# Apply Reject Option Classification\n",
        "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_group,\n",
        "                                  privileged_groups=privileged_group, metric_name=\"Equal opportunity difference\",\n",
        "                                 low_class_thresh=0.3, high_class_thresh=0.8, num_class_thresh=100, num_ROC_margin=50,\n",
        "                                 metric_ub=0.05, metric_lb=-0.05)\n",
        "\n",
        "test_predictions = ROC.fit_predict(dataset_test, dataset_testpred)\n",
        "\n",
        "# Evaluate the classifier's performance with fairness intervention\n",
        "metric_with_fairness = ClassificationMetric(\n",
        "    dataset_test_bld,\n",
        "    test_predictions,\n",
        "    unprivileged_groups=unprivileged_group,\n",
        "    privileged_groups=privileged_group\n",
        ")\n",
        "\n",
        "print(\"Performance with fairness intervention (EqualizedOdds):\")\n",
        "print(\"Accuracy: {:.6f}\".format(metric_predicted_dataset.accuracy()))\n",
        "print(\"Disparate Impact: {:.6f}\".format(metric_predicted_dataset.disparate_impact()))\n",
        "print(\"Mean Difference: {:.6f}\".format(metric_predicted_dataset.mean_difference()))\n",
        "print(f\"Statistical Parity Difference: {metric_predicted_dataset.statistical_parity_difference()}\")\n",
        "print(f\"Equal Opportunity Difference: {metric_predicted_dataset.equal_opportunity_difference()}\")\n",
        "print(f\"Predictive Equality: {metric_predicted_dataset.false_positive_rate_difference()}\")\n",
        "print(\"Difference in True Positive Rates (Unprivileged - Privileged) = %f\" % metric_with_fairness.true_positive_rate_difference())\n",
        "print(\"Difference in False Positive Rates (Unprivileged - Privileged) = %f\" % metric_with_fairness.false_positive_rate_difference())\n"
      ]
    }
  ]
}