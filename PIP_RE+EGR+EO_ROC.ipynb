{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbjJXqq08fcmMAIH5frMNz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmfara/IF-EA/blob/main/PIP_RE%2BEGR%2BEO_ROC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDxUw-rYT9kv"
      },
      "outputs": [],
      "source": [
        "# Data handling and visualization\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# AIF360 fairness library\n",
        "from aif360.datasets import StandardDataset, BinaryLabelDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
        "from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing\n",
        "from aif360.algorithms.inprocessing import ExponentiatedGradientReduction, AdversarialDebiasing\n",
        "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
        "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv(COMPAS dataset)\n",
        "\n",
        "X = data.drop(['two_year_recid'], axis =1)\n",
        "y = data[['two_year_recid']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=101, shuffle =True, stratify = y)\n",
        "\n",
        "dataset_train = pd.concat([X_train, y_train], axis=1)\n",
        "dataset_test = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "dataset_train = dataset_train.reset_index(drop=True)\n",
        "dataset_test = dataset_test.reset_index(drop=True)\n",
        "\n",
        "# Define favorable and unfavorable labels\n",
        "favorable_label = 1\n",
        "unfavorable_label = 0\n",
        "\n",
        "# Define protected attribute names and privileged group\n",
        "protected_attribute_names = ['race']\n",
        "privileged_group = [{'race': 1}]\n",
        "unprivileged_group = [{'race' : 0}]\n",
        "\n",
        "dir = DisparateImpactRemover(repair_level=1, sensitive_attribute=\"race\")\n",
        "\n",
        "# Convert the training and test set to Binary label datasets\n",
        "dataset_train_bld = BinaryLabelDataset(df=dataset_train,\n",
        "                             label_names=['two_year_recid'],\n",
        "                             favorable_label=favorable_label,\n",
        "                             unfavorable_label=unfavorable_label,\n",
        "                             protected_attribute_names=protected_attribute_names,\n",
        "                             privileged_protected_attributes=privileged_group)\n",
        "\n",
        "dataset_test_bld = BinaryLabelDataset(df=dataset_test,\n",
        "                                      label_names=['two_year_recid'],\n",
        "                                      favorable_label=favorable_label,\n",
        "                                      unfavorable_label=unfavorable_label,\n",
        "                                      protected_attribute_names=protected_attribute_names,\n",
        "                                      privileged_protected_attributes=privileged_group)\n",
        "\n",
        "#Preprocessing technique\n",
        "# Applying Reweighing\n",
        "RW = Reweighing(unprivileged_groups=unprivileged_group, privileged_groups=privileged_group)\n",
        "\n",
        "# Fit and transform the training data\n",
        "re_dataset = RW.fit_transform(dataset_train_bld)\n",
        "\n",
        "#setting the base classifier\n",
        "base_classifier = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "\n",
        "#Inprocessing technique\n",
        "inprocess_algorithm = ExponentiatedGradientReduction(base_classifier, constraints=\"DemographicParity\",\n",
        "                                                     eps = 0.02, drop_prot_attr = False)\n",
        "\n",
        "inprocess_algorithm.fit(re_dataset)\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = inprocess_algorithm.predict(dataset_test_bld)\n",
        "\n",
        "# Evaluate the model's accuracy and fairness\n",
        "accuracy = accuracy_score(dataset_test_bld.labels, predictions.labels)\n",
        "metric_predicted_dataset = ClassificationMetric(dataset_test_bld, predictions, privileged_group, unprivileged_group)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Performance with fairness intervention (Reject Option Classification):\")\n",
        "print(\"Accuracy: {:.2f}\".format(metric_predicted_dataset.accuracy()))\n",
        "print(\"Disparate Impact: {:.2f}\".format(metric_predicted_dataset.disparate_impact()))\n",
        "print(\"Mean Difference: {:.2f}\".format(metric_predicted_dataset.mean_difference()))\n",
        "print(f\"Statistical Parity Difference: {metric_predicted_dataset.statistical_parity_difference()}\")\n",
        "print(f\"Equal Opportunity Difference: {metric_predicted_dataset.equal_opportunity_difference()}\")\n",
        "print(f\"Predictive Equality: {metric_predicted_dataset.false_positive_rate_difference()}\")\n",
        "\n",
        "#Applying the Postprocessing: EO\n",
        "# Initialize EqualizedOdds\n",
        "eo = EqOddsPostprocessing(unprivileged_groups=unprivileged_group,\n",
        "                                  privileged_groups=privileged_group)\n",
        "\n",
        "# Fit the EqualizedOdds model\n",
        "test_predictions = eo.fit_predict(dataset_test_bld, predictions)\n",
        "\n",
        "metric_with_fairness = ClassificationMetric(\n",
        "    dataset_test_bld,\n",
        "    test_predictions,\n",
        "    unprivileged_groups=unprivileged_group,\n",
        "    privileged_groups=privileged_group\n",
        ")\n",
        "\n",
        "print(\"Performance with fairness intervention (EO):\")\n",
        "print(\"Accuracy: {:.2f}\".format(metric_with_fairness.accuracy()))\n",
        "print(\"Disparate Impact: {:.2f}\".format(metric_with_fairness.disparate_impact()))\n",
        "print(\"Mean Difference: {:.2f}\".format(metric_with_fairness.mean_difference()))\n",
        "statistical_parity_difference = metric_with_fairness.statistical_parity_difference()\n",
        "equal_opportunity_difference = metric_with_fairness.equal_opportunity_difference()\n",
        "print(f\"Statistical Parity Difference: {statistical_parity_difference}\")\n",
        "print(f\"Disparate Impact: {disparate_impact}\")\n",
        "print(f\"Equal Opportunity Difference: {equal_opportunity_difference}\")\n",
        "print(\"Difference in True Positive Rates (Unprivileged - Privileged) = %f\" % metric_with_fairness.true_positive_rate_difference())\n",
        "print(\"Difference in False Positive Rates (Unprivileged - Privileged) = %f\" % metric_with_fairness.false_positive_rate_difference())\n",
        "\n",
        "#Applying thee Postprocessing: ROC\n",
        "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_group,\n",
        "                                  privileged_groups=privileged_group, metric_name=\"Equal opportunity difference\",\n",
        "                                 low_class_thresh=0.3, high_class_thresh=0.8, num_class_thresh=100, num_ROC_margin=50,\n",
        "                                 metric_ub=0.05, metric_lb=-0.05)\n",
        "\n",
        "\n",
        "test_predictions = ROC.fit_predict(dataset_test_bld, predictions)\n",
        "\n",
        "metric_with_fairness = ClassificationMetric(\n",
        "    dataset_test_bld,\n",
        "    test_predictions,\n",
        "    unprivileged_groups=unprivileged_group,\n",
        "    privileged_groups=privileged_group\n",
        ")\n",
        "\n",
        "print(\"Performance with fairness intervention (Reject Option Classification):\")\n",
        "print(\"Accuracy: {:.6f}\".format(metric_with_fairness.accuracy()))\n",
        "print(\"Disparate Impact: {:.6f}\".format(metric_with_fairness.disparate_impact()))\n",
        "print(\"Mean Difference: {:.6f}\".format(metric_with_fairness.mean_difference()))\n",
        "statistical_parity_difference = metric_with_fairness.statistical_parity_difference()\n",
        "equal_opportunity_difference = metric_with_fairness.equal_opportunity_difference()\n",
        "print(f\"Statistical Parity Difference: {statistical_parity_difference}\")\n",
        "print(f\"Disparate Impact: {disparate_impact}\")\n",
        "print(f\"Equal Opportunity Difference: {equal_opportunity_difference}\")\n",
        "print(\"Difference in True Positive Rates (Unprivileged - Privileged) = %f\" % metric_with_fairness.true_positive_rate_difference())\n",
        "print(\"Difference in False Positive Rates (Unprivileged - Privileged) = %f\" % metric_with_fairness.false_positive_rate_difference())"
      ]
    }
  ]
}